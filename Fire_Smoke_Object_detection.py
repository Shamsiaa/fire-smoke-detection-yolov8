# -*- coding: utf-8 -*-
"""latest_yolov8 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nl92UzQFCE9JclLEkx7o1YAureqQt1Cy
"""

!pip install roboflow
import os
import cv2
import numpy as np
from roboflow import Roboflow
rf = Roboflow(api_key="MlrDWpGoGBtUHPpC0FRl")
project = rf.workspace("veli-t").project("firesmokedetection-5w49j")
version = project.version(3)
dataset = version.download("yolov8")

import os
import yaml

def merge_fire_classes(base_path):
    # Update class names in data.yaml using PyYAML
    yaml_path = os.path.join(base_path, "data.yaml")
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)

    # Update class names (merge "Fire" and "fire" into single "fire")
    data['names'] = ['fire', 'smoke']
    data['nc'] = 2  # number of classes

    with open(yaml_path, 'w') as f:
        yaml.dump(data, f)

    print("✅ data.yaml updated.")

    # Process label files for all splits
    for split in ['train', 'valid', 'test']:
        label_dir = os.path.join(base_path, split, 'labels')
        for filename in os.listdir(label_dir):
            if not filename.endswith('.txt'):
                continue

            filepath = os.path.join(label_dir, filename)
            with open(filepath, 'r') as f:
                lines = f.readlines()

            new_lines = []
            for line in lines:
                parts = line.strip().split()
                class_id = int(parts[0])

                # Merge Fire (1) into fire (0), smoke becomes 1
                if class_id in [0, 1]:  # Fire or fire
                    new_class = 0
                elif class_id == 2:  # smoke
                    new_class = 1
                else:
                    continue  # skip unknown class

                new_line = f"{new_class} {' '.join(parts[1:])}\n"
                new_lines.append(new_line)

            with open(filepath, 'w') as f:
                f.writelines(new_lines)

    print("✅ Label files updated.")

# Execute
base_path = '/content/FireSmokeDetection-3'
merge_fire_classes(base_path)

import os
import cv2
import matplotlib.pyplot as plt

# Class names (make sure they match your `data.yaml`)
CLASS_NAMES = ['fire', 'smoke']

# Base path to the dataset
base_path = '/content/FireSmokeDetection-3'

# Function to draw bounding boxes
def draw_bboxes(image_path, label_path):
    image = cv2.imread(image_path)
    height, width = image.shape[:2]

    with open(label_path, 'r') as f:
        for line in f.readlines():
            parts = line.strip().split()
            class_id = int(parts[0])
            x_center, y_center, w, h = map(float, parts[1:])

            # Convert YOLO format to pixel coordinates
            x1 = int((x_center - w / 2) * width)
            y1 = int((y_center - h / 2) * height)
            x2 = int((x_center + w / 2) * width)
            y2 = int((y_center + h / 2) * height)

            color = (0, 0, 255) if class_id == 0 else (0, 255, 255)  # fire=red, smoke=yellow
            label = CLASS_NAMES[class_id]

            # Draw box and label
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# --- Display a few example images ---
def show_examples(split='train', num_images=5):
    image_dir = os.path.join(base_path, split, 'images')
    label_dir = os.path.join(base_path, split, 'labels')

    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]

    for img_file in image_files[:num_images]:
        img_path = os.path.join(image_dir, img_file)
        label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')

        if not os.path.exists(label_path):
            continue  # skip if no label

        image_with_boxes = draw_bboxes(img_path, label_path)

        plt.figure(figsize=(8, 6))
        plt.imshow(image_with_boxes)
        plt.title(img_file)
        plt.axis('off')
        plt.show()

# Run for a few train images
show_examples(split='train', num_images=10)

!pip install ultralytics

import os
import random
import shutil

def create_subset(source_dir, dest_dir, num_samples):
    os.makedirs(os.path.join(dest_dir, 'images'), exist_ok=True)
    os.makedirs(os.path.join(dest_dir, 'labels'), exist_ok=True)

    image_files = os.listdir(os.path.join(source_dir, 'images'))
    random.shuffle(image_files)
    selected_files = image_files[:num_samples]

    for file in selected_files:
        shutil.copy(os.path.join(source_dir, 'images', file), os.path.join(dest_dir, 'images', file))
        label_file = file.replace('.jpg', '.txt').replace('.png', '.txt')  # depending on your extension
        shutil.copy(os.path.join(source_dir, 'labels', label_file), os.path.join(dest_dir, 'labels', label_file))

base = '/content/FireSmokeDetection-3'
subset_path = '/content/FireSmokeSubset'

# Create subsets
create_subset(f'{base}/train', f'{subset_path}/train', 4000)
create_subset(f'{base}/valid', f'{subset_path}/valid', 400)
create_subset(f'{base}/test', f'{subset_path}/test', 200)

# Copy the YAML file (you'll edit it in next step)
shutil.copy(f'{base}/data.yaml', f'{subset_path}/data.yaml')

yaml_path = f'{subset_path}/data.yaml'

with open(yaml_path, 'r') as file:
    lines = file.readlines()

with open(yaml_path, 'w') as file:
    for line in lines:
        if line.startswith('train:'):
            file.write("train: /content/FireSmokeSubset/train/images\n")
        elif line.startswith('val:'):
            file.write("val: /content/FireSmokeSubset/valid/images\n")
        elif line.startswith('test:'):
            file.write("test: /content/FireSmokeSubset/test/images\n")
        else:
            file.write(line)

# Update the data.yaml path to point to our subset
yaml_path = '/content/FireSmokeSubset/data.yaml'

# Verify the dataset configuration
with open(yaml_path) as f:
    data = yaml.safe_load(f)
    print("Dataset configuration:")
    print(data)

# Install required packages
!pip install ultralytics roboflow clearml

from ultralytics import YOLO
import os
import yaml
from clearml import Task

# Initialize ClearML for experiment tracking (optional but recommended)
# task = Task.init(project_name='FireSmokeDetection', task_name='YOLOv8_training')

# Load the model
model = YOLO("yolov8s.pt")  # load a pretrained model

training_params = {
    'data': yaml_path,
    'epochs': 150,
    'batch': 16,  # Start with batch size 16
    'imgsz': 640,
    'device': 0,  # Use GPU
    'workers': 8,
    'optimizer': 'auto',  # Automatically select the best optimizer
    'lr0': 0.01,  # Initial learning rate
    'cos_lr': True,  # Use cosine learning rate scheduler
    'patience': 10,  # Early stopping patience
    'save_period': 10,  # Save checkpoint every 10 epochs
    'exist_ok': True,  # Overwrite existing files
    'val': True,  # Validate during training
    'cache': 'ram',  # Cache dataset in RAM for faster training
    'single_cls': False,  # Multi-class training
    'rect': False,  # Rectangular training
    'plots': True,  # Save plots during training
    'close_mosaic': 10,  # Disable mosaic augmentation last 10 epochs
    'project': '/content/runs/detect',
    'name': 'fire_smoke_detection',
    'pretrained': True,
    'verbose': True
}
results = model.train(**training_params)

"""train"""

# If the initial batch size causes memory issues, we'll reduce it and retrain
try:
    results = model.train(**training_params)
except RuntimeError as e:
    if 'CUDA out of memory' in str(e):
        print("\n⚠️ GPU memory exhausted! Reducing batch size...")
        training_params['batch'] = 8  # Reduce batch size
        results = model.train(**training_params)
    else:
        raise e

metrics = model.val(
    data=yaml_path,
    batch=training_params['batch'],
    imgsz=training_params['imgsz'],
    conf=0.5,
    iou=0.45,
    split='test',
    save_json=True,
    save_hybrid=False,
    plots=True,
    save=True,
    save_conf=True
)a

print(f"Test mAP@0.5: {metrics.box.map50}")  # For IoU=0.5
print(f"Test mAP@0.5:0.95: {metrics.box.map}")  # For IoU=0.5:0.95

!zip -r runs.zip /content/runs
!zip -r FireSmokeSubset.zip /content/FireSmokeSubset

from google.colab import drive
drive.mount('/content/drive')
!cp -r /content/runs /content/drive/MyDrive/
!cp -r /content/FireSmokeSubset /content/drive/MyDrive/

from google.colab import files
files.download('runs.zip')
files.download('FireSmokeSubset.zip')

# Visualize training results
from IPython.display import Image

# Display training results
Image(filename=f'/content/runs/detect/fire_smoke_detection/results.png', width=1000)

# Display validation predictions
Image(filename=f'/content/runs/detect/fire_smoke_detection/val_batch0_pred.jpg', width=1000)

"""visualization"""

# Plotting learning curves (additional visualization)
import matplotlib.pyplot as plt
import pandas as pd

# Load training results
results_csv = pd.read_csv('/content/runs/detect/fire_smoke_detection/results.csv')

# Plot metrics
plt.figure(figsize=(15, 10))
plt.subplot(2, 2, 1)
plt.plot(results_csv['epoch'], results_csv['train/box_loss'], label='Train Box Loss')
plt.plot(results_csv['epoch'], results_csv['val/box_loss'], label='Validation Box Loss')
plt.title('Box Loss')
plt.legend()

plt.subplot(2, 2, 2)
plt.plot(results_csv['epoch'], results_csv['train/cls_loss'], label='Train Class Loss')
plt.plot(results_csv['epoch'], results_csv['val/cls_loss'], label='Validation Class Loss')
plt.title('Class Loss')
plt.legend()

plt.subplot(2, 2, 3)
plt.plot(results_csv['epoch'], results_csv['metrics/precision'], label='Precision')
plt.plot(results_csv['epoch'], results_csv['metrics/recall'], label='Recall')
plt.title('Precision & Recall')
plt.legend()

plt.subplot(2, 2, 4)
plt.plot(results_csv['epoch'], results_csv['metrics/mAP50'], label='mAP@0.5')
plt.plot(results_csv['epoch'], results_csv['metrics/mAP50-95'], label='mAP@0.5:0.95')
plt.title('mAP Metrics')
plt.legend()

plt.tight_layout()
plt.show()

import pandas as pd
results_csv = pd.read_csv('/content/runs/detect/fire_smoke_detection/results.csv')
print(results_csv.columns.tolist())  # List all columns

import pandas as pd

# Load results
results_csv = pd.read_csv('/content/runs/detect/fire_smoke_detection/results.csv')

# Get best epochs and mAP values (class B = ? Check your data.yaml)
best_epoch_map50 = results_csv['metrics/mAP50(B)'].idxmax() + 1
best_map50 = results_csv['metrics/mAP50(B)'].max()

best_epoch_map50_95 = results_csv['metrics/mAP50-95(B)'].idxmax() + 1
best_map50_95 = results_csv['metrics/mAP50-95(B)'].max()

print(f"Best mAP@0.5 (Class B): {best_map50:.2f} at epoch {best_epoch_map50}")
print(f"Best mAP@0.5:0.95 (Class B): {best_map50_95:.2f} at epoch {best_epoch_map50_95}")

"""Evaluate"""



!ls /content/runs/detect/fire_smoke_detection

from ultralytics.utils.plots import plot_confusion_matrix
plot_confusion_matrix('/content/runs/detect/fire_smoke_detection/confusion_matrix_normalized.json', save_dir='/content/runs/detect/fire_smoke_detection')
import pandas as pd
import matplotlib.pyplot as plt

results = pd.read_csv('/content/runs/detect/fire_smoke_detection/results.csv')

# F1-Score vs. Confidence Threshold
plt.figure(figsize=(10, 5))
plt.plot(results['metrics/precision'], results['metrics/recall'], label='Precision-Recall')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('PR Curve')
plt.legend()
plt.show()

from PIL import Image
import glob

# Display test-set predictions
test_images = glob.glob('/content/runs/detect/fire_smoke_detection/test*.jpg')
for img_path in test_images[:5]:  # Show first 5
    display(Image.open(img_path))

"""view test results"""

!zip -r /content/training_results.zip /content/runs/detect/fire_smoke_detection